//
//  SquatDetector.swift
//  NyaSquat
//
//  ã‚«ãƒ¡ãƒ© â†’ Visionéª¨æ ¼æ¤œå‡º â†’ ã‚¹ã‚¯ãƒ¯ãƒƒãƒˆåˆ¤å®š
//  FIX: actor isolationå•é¡Œã‚’ä¿®æ­£ - poseRequestã‚’captureOutputå†…ã§ãƒ­ãƒ¼ã‚«ãƒ«ç”Ÿæˆ
//  FIX: captureSessionã‚’å…¬é–‹ã—ã¦ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ¬ã‚¤ãƒ¤ãƒ¼ã«æ¸¡ã›ã‚‹ã‚ˆã†ã«
//

import AVFoundation
import Vision
import SwiftUI
import Combine

enum SquatPhase {
    case standing
    case squatting
}

@MainActor
final class SquatDetector: NSObject, ObservableObject {
    @Published var bodyPoints: [VNHumanBodyPoseObservation.JointName: VNRecognizedPoint] = [:]
    @Published var kneeAngle: Double = 180
    @Published var phase: SquatPhase = .standing
    @Published var isCameraAvailable: Bool = false
    @Published var isPersonDetected: Bool = false

    var onSquatCompleted: (() -> Void)?

    // ã‚«ãƒ¡ãƒ©ã‚»ãƒƒã‚·ãƒ§ãƒ³ï¼ˆãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ç”¨ã«å…¬é–‹ï¼‰
    private(set) var captureSession: AVCaptureSession?

    // EMA smoothing
    private var smoothedAngle: Double = 180
    private let smoothingFactor: Double = 0.3

    // Cooldown
    private var lastCountTime: Date = .distantPast
    private let cooldownInterval: TimeInterval = 0.5

    // Thresholds
    private let standingThreshold: Double = 160
    private let squattingThreshold: Double = 100

    func startCamera() {
        let session = AVCaptureSession()
        session.sessionPreset = .medium

        guard let device = AVCaptureDevice.default(.builtInWideAngleCamera, for: .video, position: .unspecified),
              let input = try? AVCaptureDeviceInput(device: device) else {
            print("ğŸ± [SquatDetector] ã‚«ãƒ¡ãƒ©ãƒ‡ãƒã‚¤ã‚¹å–å¾—å¤±æ•—")
            isCameraAvailable = false
            return
        }

        guard session.canAddInput(input) else {
            print("ğŸ± [SquatDetector] ã‚«ãƒ¡ãƒ©å…¥åŠ›è¿½åŠ å¤±æ•—")
            isCameraAvailable = false
            return
        }
        session.addInput(input)

        let output = AVCaptureVideoDataOutput()
        output.setSampleBufferDelegate(self, queue: DispatchQueue(label: "squat.camera"))
        output.alwaysDiscardsLateVideoFrames = true

        guard session.canAddOutput(output) else {
            print("ğŸ± [SquatDetector] ãƒ“ãƒ‡ã‚ªå‡ºåŠ›è¿½åŠ å¤±æ•—")
            isCameraAvailable = false
            return
        }
        session.addOutput(output)

        captureSession = session
        isCameraAvailable = true
        print("ğŸ± [SquatDetector] ã‚«ãƒ¡ãƒ©ã‚»ãƒƒã‚·ãƒ§ãƒ³æ§‹æˆå®Œäº†ã€èµ·å‹•ä¸­...")

        DispatchQueue.global(qos: .userInitiated).async {
            session.startRunning()
            print("ğŸ± [SquatDetector] ã‚«ãƒ¡ãƒ©ã‚»ãƒƒã‚·ãƒ§ãƒ³ startRunning å®Œäº†")
        }
    }

    func stopCamera() {
        captureSession?.stopRunning()
        captureSession = nil
        isCameraAvailable = false
        print("ğŸ± [SquatDetector] ã‚«ãƒ¡ãƒ©åœæ­¢")
    }

    private func processObservation(_ observation: VNHumanBodyPoseObservation) {
        guard let joints = try? observation.recognizedPoints(.all) else { return }

        let (leftAngle, rightAngle) = AngleCalculator.kneeAngles(from: observation)

        let rawAngle: Double
        switch (leftAngle, rightAngle) {
        case let (l?, r?): rawAngle = (l + r) / 2
        case let (l?, nil): rawAngle = l
        case let (nil, r?): rawAngle = r
        case (nil, nil): return
        }

        // EMA smoothing
        smoothedAngle = smoothedAngle * (1 - smoothingFactor) + rawAngle * smoothingFactor

        self.bodyPoints = joints
        self.kneeAngle = self.smoothedAngle
        self.isPersonDetected = true
        self.updatePhase()
    }

    private func updatePhase() {
        let angle = smoothedAngle

        switch phase {
        case .standing:
            if angle < squattingThreshold {
                phase = .squatting
            }
        case .squatting:
            if angle > standingThreshold {
                let now = Date()
                if now.timeIntervalSince(lastCountTime) > cooldownInterval {
                    lastCountTime = now
                    phase = .standing
                    onSquatCompleted?()
                } else {
                    phase = .standing
                }
            }
        }
    }
}

// MARK: - AVCaptureVideoDataOutputSampleBufferDelegate
// FIX: poseRequestã‚’captureOutputå†…ã§ãƒ­ãƒ¼ã‚«ãƒ«ç”Ÿæˆã—ã¦ actor isolation å•é¡Œã‚’å›é¿
extension SquatDetector: AVCaptureVideoDataOutputSampleBufferDelegate {
    nonisolated func captureOutput(
        _ output: AVCaptureOutput,
        didOutput sampleBuffer: CMSampleBuffer,
        from connection: AVCaptureConnection
    ) {
        guard let pixelBuffer = CMSampleBufferGetImageBuffer(sampleBuffer) else { return }

        // ãƒ­ãƒ¼ã‚«ãƒ«ã§ãƒªã‚¯ã‚¨ã‚¹ãƒˆç”Ÿæˆï¼ˆMainActorãƒ—ãƒ­ãƒ‘ãƒ†ã‚£ã¸ã®ã‚¢ã‚¯ã‚»ã‚¹ã‚’å›é¿ï¼‰
        let request = VNDetectHumanBodyPoseRequest()
        let handler = VNImageRequestHandler(cvPixelBuffer: pixelBuffer, options: [:])

        do {
            try handler.perform([request])
        } catch {
            print("ğŸ± [SquatDetector] Vision performå¤±æ•—: \(error)")
            return
        }

        guard let observation = request.results?.first else {
            Task { @MainActor in
                self.isPersonDetected = false
            }
            return
        }

        Task { @MainActor in
            self.processObservation(observation)
        }
    }
}
